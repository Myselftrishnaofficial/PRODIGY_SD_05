import csv
import requests
from bs4 import BeautifulSoup

def scrape_eCommerce_website(url):
    # Send a GET request to the URL
    response = requests.get('https://flipkart.com')

    if response.status_code == 200:
        # Parse the HTML content of the page
        soup = BeautifulSoup(response.content, 'html.parser')

        # Extract product information (modify this based on the HTML structure of the website)
        product_names = [name.text.strip() for name in soup.find_all('div', class_='product-name')]
        product_prices = [price.text.strip() for price in soup.find_all('span', class_='product-price')]
        product_ratings = [rating.text.strip() for rating in soup.find_all('span', class_='product-rating')]

        # Store the data in a CSV file
        with open('product_data.csv', 'w', newline='') as csvfile:
            fieldnames = ['Name', 'Price', 'Rating']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

            # Write the header
            writer.writeheader()

            # Write the product data
            for name, price, rating in zip(product_names, product_prices, product_ratings):
                writer.writerow({'Name': name, 'Price': price, 'Rating': rating})

        print('Data has been successfully scraped and saved to product_data.csv')

    else:
        print(f'Failed to retrieve the webpage. Status code: {response.status_code}')

# Example usage
url = 'https://flipkart.com'
scrape_eCommerce_website(url)
